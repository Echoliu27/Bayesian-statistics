S_0 =  10^3 * diag(2)
normal_age25_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=age25)
# post analysis
CORR = normal_age25_mcmc$sigma[,2]/sqrt((normal_age25_mcmc$sigma[, 1]* normal_age25_mcmc$sigma[, 4]))
quantile(normal_age25_mcmc$theta[,"theta_1"], probs = c(0.025,0.975))
quantile(normal_age25_mcmc$theta[,"theta_2"], probs = c(0.025,0.975))
quantile(CORR, probs = c(0.025,0.975))
knitr::opts_chunk$set(echo = TRUE)
library(mvtnorm)
library(coda)
# Simulate data
n = 100
set.seed(1234)
theta = c(0,0)
sigma = matrix(c(1,0.8,0.8,1),nrow=2,ncol=2)
Y = rmvnorm(n, mean = theta, sigma= sigma)
## true value
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta,sigma=sigma)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using true value of ',theta, ' and ',Sigma)))
## MLE
theta_MLE = apply(Y,2,mean)
sigma_MLE = t(Y-theta_MLE)%*%(Y-theta_MLE)/n
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta_MLE,sigma=sigma_MLE)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using MLE of ',theta, ' and ',Sigma)))
gibbs_normal = function(mu_0, Lambda_0, nu_0, S_0, n_iter, Y){
n = nrow(Y)
ybar = apply(Y,2,mean)
# initial values for Gibbs sampler
Sigma <- cov(Y)
# set null matrices to save samples
THETA <- SIGMA <- NULL
# first set number of iterations and burn-in, then set seed
burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
Lambda_n <- solve(solve(Lambda_0) + n*solve(Sigma))
mu_n <- Lambda_n %*% (solve(Lambda_0)%*%mu_0 + n*solve(Sigma)%*%ybar)
theta <- rmvnorm(1,mu_n,Lambda_n)
# update Sigma
S_theta <- (t(Y)-c(theta))%*%t(t(Y)-c(theta))
S_n <- S_0 + S_theta
nu_n <- nu_0 + n
Sigma <- riwish(nu_n, S_n)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
return(list(theta = THETA, sigma = SIGMA))
}
# Initialize the hyperparameters
ybar = apply(Y,2,mean)
mu_0 = c(0,0)
Lambda_0 = matrix(c(1,0.5,0.5,1),nrow=2, ncol=2)
nu_0 = 4
S_0 =  matrix(c(1,0,0,1),nrow=2, ncol=2)
# Performs Gibbs Sampling
normal_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=Y)
# Diagnostics check (autocorrelation plot seems reasonable)
library(coda)
THETA.mcmc <- mcmc(normal_mcmc$THETA,start=1);
knitr::opts_chunk$set(echo = TRUE)
library(mvtnorm)
library(coda)
library(MCMCpack)
gibbs_normal = function(mu_0, Lambda_0, nu_0, S_0, n_iter, Y){
n = nrow(Y)
ybar = apply(Y,2,mean)
# initial values for Gibbs sampler
Sigma <- cov(Y)
# set null matrices to save samples
THETA <- SIGMA <- NULL
# first set number of iterations and burn-in, then set seed
burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
Lambda_n <- solve(solve(Lambda_0) + n*solve(Sigma))
mu_n <- Lambda_n %*% (solve(Lambda_0)%*%mu_0 + n*solve(Sigma)%*%ybar)
theta <- rmvnorm(1,mu_n,Lambda_n)
# update Sigma
S_theta <- (t(Y)-c(theta))%*%t(t(Y)-c(theta))
S_n <- S_0 + S_theta
nu_n <- nu_0 + n
Sigma <- riwish(nu_n, S_n)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
return(list(theta = THETA, sigma = SIGMA))
}
# Initialize the hyperparameters
ybar = apply(Y,2,mean)
mu_0 = c(0,0)
Lambda_0 = matrix(c(1,0.5,0.5,1),nrow=2, ncol=2)
nu_0 = 4
S_0 =  matrix(c(1,0,0,1),nrow=2, ncol=2)
# Performs Gibbs Sampling
normal_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=Y)
# Diagnostics check (autocorrelation plot seems reasonable)
library(coda)
THETA.mcmc <- mcmc(normal_mcmc$THETA,start=1);
# THETA
apply(normal_mcmc$THETA, 2, mean); # Bayes estimate
## Simulate data
n = 100
set.seed(1234)
theta = c(0,0)
sigma = matrix(c(1,0.8,0.8,1),nrow=2,ncol=2)
Y = rmvnorm(n, mean = theta, sigma= sigma)
## true value
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta,sigma=sigma)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using true value of ',theta, ' and ',Sigma)))
## MLE
theta_MLE = apply(Y,2,mean)
sigma_MLE = t(Y-theta_MLE)%*%(Y-theta_MLE)/n
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta_MLE,sigma=sigma_MLE)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using MLE of ',theta, ' and ',Sigma)))
library(mvtnorm)
library(MCMCpack)
require(tidyverse)
# (a)
# Simulate data
n = 100
set.seed(1234)
theta = c(0,0)
sigma = matrix(c(1,0.8,0.8,1),nrow=2,ncol=2)
Y = rmvnorm(n, mean = theta, sigma= sigma)
## true value
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta,sigma=sigma)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using true value of ',theta, ' and ',Sigma)))
## MLE
theta_MLE = apply(Y,2,mean)
sigma_MLE = t(Y-theta_MLE)%*%(Y-theta_MLE)/n
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta_MLE,sigma=sigma_MLE)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using MLE of ',theta, ' and ',Sigma)))
gibbs_normal = function(mu_0, Lambda_0, nu_0, S_0, n_iter, Y){
n = nrow(Y)
ybar = apply(Y,2,mean)
## Gibbs Sampler
#Initial values for Gibbs sampler
Sigma <- cov(Y)
#Set null matrices to save samples
THETA <- SIGMA <- NULL
#first set number of iterations and burn-in, then set seed
burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
##update theta using its full conditional
Lambda_n <- solve(solve(Lambda_0) + n*solve(Sigma))
mu_n <- Lambda_n %*% (solve(Lambda_0)%*%mu_0 + n*solve(Sigma)%*%ybar)
theta <- rmvnorm(1,mu_n,Lambda_n)
#update Sigma
S_theta <- (t(Y)-c(theta))%*%t(t(Y)-c(theta))
S_n <- S_0 + S_theta
nu_n <- nu_0 + n
Sigma <- riwish(nu_n, S_n)
#save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
return(list(theta = THETA, sigma = SIGMA))
}
# Initialize the hyperparameters
ybar = apply(Y,2,mean)
# Initialize the hyperparameters
mu_0 = c(0,0)
Lambda_0 = matrix(c(1,0.5,0.5,1),nrow=2, ncol=2)
nu_0 = 4
S_0 =  matrix(c(1,0,0,1),nrow=2, ncol=2)
# Performs Gibbs Sampling
normal_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=Y)
# diagnostics check (autocorrelation plot seems reasonable)
library(coda)
THETA.mcmc <- mcmc(normal_mcmc$THETA,start=1);
View(normal_mcmc)
THETA.mcmc <- mcmc(normal_mcmc$theta,start=1);
plot(THETA.mcmc[,"theta_1"])
autocorr.plot(THETA.mcmc[,"theta_1"])
gibbs_normal = function(mu_0, Lambda_0, nu_0, S_0, n_iter, Y){
n = nrow(Y)
ybar = apply(Y,2,mean)
# initial values for Gibbs sampler
Sigma <- cov(Y)
# set null matrices to save samples
THETA <- SIGMA <- NULL
# first set number of iterations and burn-in, then set seed
burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
Lambda_n <- solve(solve(Lambda_0) + n*solve(Sigma))
mu_n <- Lambda_n %*% (solve(Lambda_0)%*%mu_0 + n*solve(Sigma)%*%ybar)
theta <- rmvnorm(1,mu_n,Lambda_n)
# update Sigma
S_theta <- (t(Y)-c(theta))%*%t(t(Y)-c(theta))
S_n <- S_0 + S_theta
nu_n <- nu_0 + n
Sigma <- riwish(nu_n, S_n)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
return(list(theta = THETA, sigma = SIGMA))
}
# Initialize the hyperparameters
ybar = apply(Y,2,mean)
mu_0 = c(0,0)
Lambda_0 = matrix(c(1,0.5,0.5,1),nrow=2, ncol=2)
nu_0 = 4
S_0 =  matrix(c(1,0,0,1),nrow=2, ncol=2)
# Performs Gibbs Sampling
normal_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=Y)
# Diagnostics check (autocorrelation plot seems reasonable)
library(coda)
THETA.mcmc <- mcmc(normal_mcmc$theta,start=1);
plot(THETA.mcmc[,"theta_1"])
autocorr.plot(THETA.mcmc[,"theta_1"])
## Simulate data
n = 100
set.seed(1234)
theta = c(0,0)
sigma = matrix(c(1,0.8,0.8,1),nrow=2,ncol=2)
Y = rmvnorm(n, mean = theta, sigma= sigma)
## true value
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta,sigma=sigma)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using true value of ',theta, ' and ',Sigma)))
## MLE
theta_MLE = apply(Y,2,mean)
sigma_MLE = t(Y-theta_MLE)%*%(Y-theta_MLE)/n
x.points <- seq(-2.5,2.5,length.out=100)
y.points <- x.points
z <- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
for (j in 1:100) {
z[i,j] <- dmvnorm(c(x.points[i],y.points[j]),
mean=theta_MLE,sigma=sigma_MLE)
}
}
contour(x.points,y.points,z, main= expression(paste('Contour plot using MLE of ',theta, ' and ',Sigma)))
gibbs_normal = function(mu_0, Lambda_0, nu_0, S_0, n_iter, Y){
n = nrow(Y)
ybar = apply(Y,2,mean)
# initial values for Gibbs sampler
Sigma <- cov(Y)
# set null matrices to save samples
THETA <- SIGMA <- NULL
# first set number of iterations and burn-in, then set seed
burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
Lambda_n <- solve(solve(Lambda_0) + n*solve(Sigma))
mu_n <- Lambda_n %*% (solve(Lambda_0)%*%mu_0 + n*solve(Sigma)%*%ybar)
theta <- rmvnorm(1,mu_n,Lambda_n)
# update Sigma
S_theta <- (t(Y)-c(theta))%*%t(t(Y)-c(theta))
S_n <- S_0 + S_theta
nu_n <- nu_0 + n
Sigma <- riwish(nu_n, S_n)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
return(list(theta = THETA, sigma = SIGMA))
}
# Initialize the hyperparameters
ybar = apply(Y,2,mean)
mu_0 = c(0,0)
Lambda_0 = matrix(c(1,0.5,0.5,1),nrow=2, ncol=2)
nu_0 = 4
S_0 =  matrix(c(1,0,0,1),nrow=2, ncol=2)
# Performs Gibbs Sampling
normal_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=Y)
# Diagnostics check (autocorrelation plot seems reasonable)
THETA.mcmc <- mcmc(normal_mcmc$theta,start=1);
plot(THETA.mcmc[,"theta_1"])
autocorr.plot(THETA.mcmc[,"theta_1"])
# THETA
apply(normal_mcmc$theta, 2, mean); # Bayes estimate
theta_MLE; # MLE
theta # truth
# SIGMA
apply(normal_mcmc$sigma, 2, mean) # Bayes estimae
theta_SIGMA # MLE
# THETA
apply(normal_mcmc$theta, 2, mean); # Bayes estimate
theta_MLE; # MLE
theta # truth
# SIGMA
apply(normal_mcmc$sigma, 2, mean) # Bayes estimae
sigma_MLE # MLE
sigma # truth
n = 100
m = 15 # number of datasets
mu_0 = c(55,55)
Lambda_0 = matrix(c(225,180,180,225),nrow=2, ncol=2)
nu_0 = 4
S_0 =  Lambda_0
# Set null matrices to save samples
THETA <- SIGMA <- Y.prior <- NULL
for (i in 1:m){
# sample
theta = rmvnorm(1, mu_0, Lambda_0)
Sigma = riwish(nu_0, S_0)
Y = rmvnorm(n, theta, Sigma)
# generate
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
Y.prior <- rbind(Y.prior,c(Y))
}
# Plotting, visual check
ids = sample(1:m, 3)
for (id in ids){
plot(Y.prior[id, 1:100], Y.prior[id, 101:200], xlab = 'Husband Age', ylab = 'Wife Age')
abline(a=0, b=1)
}
# Hyperparameters for the priors
mu_0 = c(55,55)
Lambda_0 = matrix(c(225,180,180,225),nrow=2, ncol=2)
nu_0 = 4
S_0 =  Lambda_0
# Gibbs Sampler
normal_age_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=age)
knitr::opts_chunk$set(echo = TRUE)
library(mvtnorm)
library(coda)
library(MCMCpack)
library(MASS)
# Read in data
age = read.table('agehw.dat', header = TRUE)
# Hyperparameters for the priors
mu_0 = c(55,55)
Lambda_0 = matrix(c(225,180,180,225),nrow=2, ncol=2)
nu_0 = 4
S_0 =  Lambda_0
# Gibbs Sampler
normal_age_mcmc = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=age)
# Plots
plot(normal_age_mcmc$theta[,"theta_1"], normal_age_mcmc$theta[,"theta_2"], xlab="Husband Ages", ylab="Wife Ages", main = "Joint posterior distribution of THETA")
CORR = normal_age_mcmc$sigma[,2]/sqrt((normal_age_mcmc$sigma[, 1]* normal_age_mcmc$sigma[, 4]))
plot(density(CORR), main = "Posterior Density of Correlation Between Yh and Yw")
# 95% posterior confidence intervals for THETA and correlation coefficient
quantile(normal_age_mcmc$theta[,"theta_1"], probs = c(0.025,0.975))
quantile(normal_age_mcmc$theta[,"theta_2"], probs = c(0.025,0.975))
quantile(CORR, probs = c(0.025,0.975)) # the correlation is even higher
# Innitialize
n = nrow(age)
ybar = apply(age, 2, mean)
Sigma = cov(age)
THETA <- SIGMA <- NULL
# Gibbs Sampler
n_iter <- 1000; burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
theta <- rmvnorm(1,ybar,Sigma/n)
# update Sigma
S_theta <- (t(age)-c(ybar))%*%t(t(age)-c(ybar))
Sigma <- riwish(n+1, S_theta)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
# Correlation coefficient
CORR = normal_age_mcmc2$sigma[,2]/sqrt((normal_age_mcmc2$sigma[, 1]* normal_age_mcmc2$sigma[, 4]))
View(z)
# Innitialize
n = nrow(age)
ybar = apply(age, 2, mean)
Sigma = cov(age)
THETA <- SIGMA <- NULL
# Gibbs Sampler
n_iter <- 1000; burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
theta <- rmvnorm(1,ybar,Sigma/n)
# update Sigma
S_theta <- (t(age)-c(ybar))%*%t(t(age)-c(ybar))
Sigma <- riwish(n+1, S_theta)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
# Correlation coefficient
CORR = SIGMA[,2]/sqrt((SIGMA$sigma[, 1]* SIGMA[, 4]))
# Innitialize
n = nrow(age)
ybar = apply(age, 2, mean)
Sigma = cov(age)
THETA <- SIGMA <- NULL
# Gibbs Sampler
n_iter <- 1000; burn_in <- 0.3*n_iter
set.seed(1234)
for (s in 1:(n_iter+burn_in)){
# update theta using its full conditional
theta <- rmvnorm(1,ybar,Sigma/n)
# update Sigma
S_theta <- (t(age)-c(ybar))%*%t(t(age)-c(ybar))
Sigma <- riwish(n+1, S_theta)
# save results only past burn-in
if(s > burn_in){
THETA <- rbind(THETA,theta)
SIGMA <- rbind(SIGMA,c(Sigma))
}
}
colnames(THETA) <- c("theta_1","theta_2")
colnames(SIGMA) <- c("sigma_11","sigma_12","sigma_21","sigma_22") #symmetry in sigma
# Correlation coefficient
CORR = SIGMA[,2]/sqrt((SIGMA[, 1]* SIGMA[, 4]))
# 95% posterior confidence interval
quantile(THETA[,"theta_1"], probs = c(0.025,0.975))
quantile(THETA[,"theta_2"], probs = c(0.025,0.975))
quantile(CORR, probs = c(0.025,0.975))
# Hyperparameters for prior
mu_0 = c(0,0)
Lambda_0 = 10^5 * diag(2)
nu_0 = 3
S_0 =  10^3 * diag(2)
# Gibbs sampler
normal_age_mcmc2 = gibbs_normal(mu_0, Lambda_0, nu_0, S_0, n_iter=1000, Y=age)
# Correlation coefficient
CORR = normal_age_mcmc2$sigma[,2]/sqrt((normal_age_mcmc2$sigma[, 1]* normal_age_mcmc2$sigma[, 4]))
# 95% posterior confidence interval
quantile(normal_age_mcmc2$theta[,"theta_1"], probs = c(0.025,0.975))
quantile(normal_age_mcmc2$theta[,"theta_2"], probs = c(0.025,0.975))
quantile(CORR, probs = c(0.025,0.975)) # the correlation is even higher

---
title: "Lab 9"
author: "Bingying Liu"
date: "3/30/2020"
output: html_document
---

```{r setup, echo = F, message=F, warning=F, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(rstanarm)
require(magrittr)
library(tidyverse)
library(ggplot2)
require(loo)
require(bayesplot)
require(caret)
library(rstan)
require(HSAUR3)
```

## 1. Linear Regression
#### Frequentist Approach
```{r}
data("clouds", package = "HSAUR3")
#head(clouds)

# frequentist approach
ols <- lm(rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) + time,
          data = clouds)
summary(ols)
```

#### Exercise 1: Interpret the significant coefficients (at the 0.05 significance level).
- Using 0.05 as significance level, we can see that "seedingyes" and "seedinghes:sne" are statistically significant.
- seedingyes: when sne, cloudcover, prewetness and echomotion are zero, the change of seeding from no to yes has will increase the amount of rainfall by 15.68.
- seedingyes:sne : Holding all other variables the same, for cloud with no seeding, the effect of one unit of increase in sne is 0.4198; for cloud with seeding, the effect of one unit of increase in sne is 0.4198 - 3.1953 = -2.7755

#### Bayesian Approach
```{r}
beta0.prior <- cauchy()
beta.prior <- cauchy()

stan.glm <- stan_glm(data = clouds,
                     formula = rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) + time,
                     family = gaussian(),
                     prior = beta.prior,
                     prior_intercept = beta0.prior,
                     refresh = 0,
                     refresh = 0)
summary(stan.glm)
```


#### Exercise 2: How do the estimated coefficients compare in this glm model to those from the model fit using lm? 
- lm has larger value in positive coefficients and has smaller value in negative coefficients (which means it's more extreme and more overfitting to the data than stan.glm.)

#### Exercise 3: How do the credible intervals and standard errors of the coeffients compare?
```{r}
# 95% CI comparison
round(confint(ols, level=0.95),3)
round(posterior_interval(stan.glm, prob = 0.95), 3)
```
- In general, the standard errors of stan.glm is bigger than lm. However, credible intervals of stan.glm and lm are very similar.

## 2. Logistic Regression
```{r}
seed <- 196
admissions <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
## view the first few rows of the data
# head(admissions)
admissions$rank <- factor(admissions$rank)
admissions$admit <- factor(admissions$admit)
admissions$gre <- scale(admissions$gre)
p <- 5
n <- nrow(admissions)
```

#### Frequentist Approach
```{r}
freq.mod <- glm(admit ~. , data = admissions,
                family = binomial())
summary(freq.mod)
```


#### Exercise 4: Interpret the significant coefficients (at the 0.05 significance level).
- gre: Holding all else constant, for individual who is in rank 1, increasing gre by 1 unit is expected to increase the log-odds of being admitted by 0.2616.
- gpa: Holding all else constant, for individual who is in rank 1, increasing gpa by 1 unit is expected to increase the log-odds of being admitted by 0.8040. 
- rank2: Holding all else constant, for individual who switch from rank 1 to rank 2, log-odds of being admitted is decreased by 0.6754.
- rank3: Holding all else constant, for individual who switch from rank 1 to rank 3, log-odds of being admitted is decreased by 1.3402.
- rank4: Holding all else constant, for individual who switch from rank 1 to rank 5, log-odds of being admitted is decreased by 1.5515.

#### Weakly Informative Prior: Normal
```{r}
post1 <- stan_glm(admit ~ ., data = admissions,
                 family = binomial(link = "logit"), 
                 prior = normal(0,1), prior_intercept = normal(0,1),
                 seed = seed,
                 refresh = 0)
summary(post1)
```

#### Exercise 5: What do our choice of priors say about our beliefs? How do we interpret these normal priors?
- Choosing $N(0,1)$ means we believe that model coefficients/intercept are as likely to be positive as they are to be negative but they are highly unlikely to be far from zero.

```{r}
mcmc_areas(as.matrix(post1), prob = 0.95, prob_outer = 1)
round(coef(post1), 3)
round(posterior_interval(post1, prob = 0.95), 3)
round(confint(freq.mod, level=0.95),3) # comparison with the glm model
```


#### Exercise 6: How do the estimated coefficients compare in this model to those from the model fit using glm?
- The estimated coefficients of stan_glm are very similar (or slightly pulled towards 0) to those of glm since the bayesian regression model is using a weakly informative prior and data outweights the prior belief.

#### Exercise 7: How do the credible intervals and standard errors of the coefficients compare to the confidence intervals and standard errors from the model fit using glm?
- The credible intervals and standard errors of stan_glm are also very similar to those of glm because of the same reasons above (data outweights the prior belief).

#### Posterior predictive checks
```{r}
(loo1 <- loo(post1, save_psis = TRUE))
post0 <- stan_glm(admit ~ 1, data = admissions,
                 family = binomial(link = "logit"), 
                 prior = normal(0,1), prior_intercept = normal(0,1),
                 seed = seed,
                 refresh = 0)
(loo0 <- loo(post0, save_psis = T))

```

#### Exercise 8: Which model is better? Why?
- post1 is better than post0 since it has all covariates. This means that covariates contain useful information for predictions.

```{r}
preds <- posterior_linpred(post1, transform=TRUE)
pred <- colMeans(preds)

# classification accuracy
pr <- as.integer(pred >= 0.5)
round(mean(xor(pr,as.integer(admissions$admit==0))),3)
```

#### The Horseshoe Prior
```{r}
p0 <- 2 # prior guess for the number of relevant variables
tau0 <- p0/(p-p0) * 1/sqrt(n) # recommended by Pilronen and Vehtari (2017)
hs_prior <- hs(df=1, global_df=1, global_scale=tau0)
post2 <- stan_glm(admit ~ ., data = admissions,
                 family = binomial(link = "logit"), 
                 prior = hs_prior, prior_intercept = normal(0,1),
                 seed = seed,
                 refresh = 0)

round(coef(post2), 3)
round(posterior_interval(post2, prob = 0.95), 3)
mcmc_areas(as.matrix(post2), prob = 0.95, prob_outer = 1)
```
#### Exercise 9: How does posterior inference for the coefficients compare to when we used the weakly informative Normal prior above?
- The posterior inference for the coefficients are more pulled towards 0 when using horseshow prior than coefficients using weakly informative normal prior. Since Horseshoe places higher prior density on 0.

#### Exercise 10: How do the two models compare in terms of predictive performance? Consider using the loo function as we have been doing.

```{r}
(loo2 <- loo(post2, save_psis = T))
rstanarm::compare_models(loo1, loo2)
```

- The model using weakly informative normal prior performs better than model using horseshoe prior since elpd_diff is negative (favors first model). Also since this dataset has n>>p (number of observations greater than number of parameters), meaning that it doesn't quite make sense to use horseshoe prior which tends to shrink all coefficients towards 0.